{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af08474-cf74-4366-b226-30f1bd7390e9",
   "metadata": {},
   "source": [
    "  # **AKADEMI EDUCATION**\n",
    "# **Première cohorte (2025): Science des données et intelligence artificielle**\n",
    "#### *Phase 5: PROJET DE SCIENCE DES DONNÉES*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bb9b8-1c73-4c75-a509-402ea7127062",
   "metadata": {},
   "source": [
    "**Noms des étudiants du groupe: Riché FLEURINORD et Micka LOUIS**   \n",
    "**Rythme d’apprentissage: Autonome**  \n",
    "**Date de soutenance: 27 octobre 2025**  \n",
    "**Noms des instructeurs: Wedter JEROME et Geovany Batista Polo LAGUERRE**  \n",
    "**Lien de l’article de blog (lien du dépôt GitHub): https://github.com/richefleuriord/Bank_Customer_Churn_Prediction.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bcaf9a-150c-4e87-9728-9e964f97460f",
   "metadata": {},
   "source": [
    "# *4-Modélisation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004441f5-4726-4acc-afa1-3de96b05449e",
   "metadata": {},
   "source": [
    "## Modélisation et Sélection du Meilleur Modèle\n",
    "\n",
    "La **modélisation** est le cœur du projet de *Data Science*.  \n",
    "Elle a pour but d’entraîner plusieurs algorithmes de classification sur le jeu de données préparé afin de déterminer celui qui prédit le mieux le **churn des clients bancaires**.\n",
    "\n",
    "Après la phase de préparation, les données ont été divisées en trois ensembles :\n",
    "- **Train (70%)** : apprentissage des modèles.  \n",
    "- **Validation (15%)** : sélection des hyperparamètres optimaux.  \n",
    "- **Test (15%)** : évaluation finale et mesure de la performance réelle.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs de la modélisation\n",
    "\n",
    "- Entraîner plusieurs algorithmes performants : **Régression Logistique**, **Forêt Aléatoire**, **XGBoost**, et **Réseau de Neurones (MLP)**.  \n",
    "- Mettre en place des **pipelines complets** avec encodage, normalisation et équilibrage adaptés à chaque modèle.  \n",
    "- Utiliser la **validation croisée (cross-validation)** pour éviter le surapprentissage.  \n",
    "- Ajuster les **hyperparamètres** à l’aide de `GridSearchCV`.  \n",
    "- Comparer les modèles sur la base du **score ROC-AUC**, plus robuste que l’accuracy.  \n",
    "- Sauvegarder le **meilleur modèle** pour un déploiement fluide dans l’application Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "### Étapes principales du processus\n",
    "\n",
    "1. **Chargement des données préparées** : Importation des fichiers CSV (`X_train`, `X_val`, `X_test`, etc.) produits à l’étape précédente.  \n",
    "2. **Définition des pipelines** : Chaque modèle est encapsulé dans un pipeline intégrant son propre prétraitement (scaling, SMOTE, pondération de classes).  \n",
    "3. **Optimisation par GridSearchCV** : Recherche systématique des meilleurs hyperparamètres via validation croisée.  \n",
    "4. **Évaluation sur le jeu de validation** : Mesure de la performance (accuracy, ROC-AUC).  \n",
    "5. **Comparaison des résultats** pour déterminer le modèle le plus performant.  \n",
    "6. **Sauvegarde du modèle final** pour le déploiement.\n",
    "\n",
    "---\n",
    "\n",
    "### Spécificités par modèle\n",
    "\n",
    "| Modèle | Particularités du pipeline | Méthode d’équilibrage |\n",
    "|:--------|:----------------------------|:------------------------|\n",
    "| **Régression Logistique** | Normalisation avec `StandardScaler` | SMOTE |\n",
    "| **Random Forest** | Modèle robuste aux variables non normalisées | `class_weight='balanced'` |\n",
    "| **XGBoost** | Prise en compte du déséquilibre via `scale_pos_weight` | Pondération interne |\n",
    "| **Neural Network (MLP)** | Normalisation des données requise | Aucune, équilibrage implicite |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221f0189-78a4-40fc-8c8e-44e538ad18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Données préparées chargées et alignées avec succès !\n",
      "\n",
      " Entraînement et optimisation du modèle : LogisticRegression\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meilleurs paramètres pour LogisticRegression : {'model__C': 0.01, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "ROC-AUC (CV) : 0.7603\n",
      "\n",
      " Entraînement et optimisation du modèle : RandomForest\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meilleurs paramètres pour RandomForest : {'model__max_depth': 10, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "ROC-AUC (CV) : 0.7892\n",
      "\n",
      " Entraînement et optimisation du modèle : XGBoost\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meilleurs paramètres pour XGBoost : {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "ROC-AUC (CV) : 0.7996\n",
      "\n",
      " Entraînement et optimisation du modèle : NeuralNetwork\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meilleurs paramètres pour NeuralNetwork : {'model__activation': 'relu', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50,), 'model__learning_rate_init': 0.001}\n",
      "ROC-AUC (CV) : 0.7622\n",
      "\n",
      " Résumé des performances sur le jeu de validation :\n",
      "                Model                                         BestParams  \\\n",
      "0  LogisticRegression  {'model__C': 0.01, 'model__penalty': 'l2', 'mo...   \n",
      "1        RandomForest  {'model__max_depth': 10, 'model__min_samples_l...   \n",
      "2             XGBoost  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "3       NeuralNetwork  {'model__activation': 'relu', 'model__alpha': ...   \n",
      "\n",
      "   Val Accuracy  Val ROC-AUC  \n",
      "0      0.695333     0.771948  \n",
      "1      0.763333     0.787713  \n",
      "2      0.726667     0.798801  \n",
      "3      0.793333     0.759084  \n",
      "\n",
      " Meilleur modèle sélectionné : XGBoost sauvegardé pour le déploiement !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODELISATION OPTIMISÉE (LogReg, RF, XGBoost, NN) AVEC GRIDSEARCH\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# CHARGEMENT DES DONNÉES PRÉPARÉES\n",
    "# ============================================================\n",
    "X_train = pd.read_csv(\"../Data/X_train_prepared.csv\")\n",
    "X_val = pd.read_csv(\"../Data/X_val_prepared.csv\").reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = pd.read_csv(\"../Data/X_test_prepared.csv\").reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "y_train = pd.read_csv(\"../Data/y_train_prepared.csv\").values.ravel()\n",
    "y_val = pd.read_csv(\"../Data/y_val_prepared.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"../Data/y_test_prepared.csv\").values.ravel()\n",
    "\n",
    "print(\" Données préparées chargées et alignées avec succès !\")\n",
    "\n",
    "# ============================================================\n",
    "# SCALE POS WEIGHT POUR XGBOOST\n",
    "# ============================================================\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# ============================================================\n",
    "# PIPELINES SPÉCIFIQUES\n",
    "# ============================================================\n",
    "num_features = [\n",
    "    'CreditScore', 'Tenure', 'Balance',\n",
    "    'EstimatedSalary', 'BalanceToSalaryRatio',\n",
    "    'Satisfaction Score', 'Point Earned'\n",
    "]\n",
    "num_features = [col for col in num_features if col in X_train.columns]\n",
    "\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": ImbPipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline(steps=[\n",
    "        ('model', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline(steps=[\n",
    "        ('model', XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"NeuralNetwork\": Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', MLPClassifier(max_iter=300, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# GRILLES D’HYPERPARAMÈTRES\n",
    "# ============================================================\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__penalty\": [\"l2\"],\n",
    "        \"model__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [5, 10, 20, None],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model__n_estimators\": [100, 200, 400],\n",
    "        \"model__max_depth\": [3, 5, 6],\n",
    "        \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"model__subsample\": [0.8, 1.0]\n",
    "    },\n",
    "    \"NeuralNetwork\": {\n",
    "        \"model__hidden_layer_sizes\": [(50,), (100,), (100, 50)],\n",
    "        \"model__activation\": [\"relu\", \"tanh\"],\n",
    "        \"model__alpha\": [0.0001, 0.001],\n",
    "        \"model__learning_rate_init\": [0.001, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# GRIDSEARCHCV POUR CHAQUE MODÈLE\n",
    "# ============================================================\n",
    "best_models = {}\n",
    "results = []\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\n Entraînement et optimisation du modèle : {name}\")\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[name],\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    print(f\" Meilleurs paramètres pour {name} :\", grid.best_params_)\n",
    "    print(f\"ROC-AUC (CV) : {grid.best_score_:.4f}\")\n",
    "\n",
    "    # Évaluation sur le jeu de validation\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_val_proba = best_model.predict_proba(X_val)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "    val_auc = roc_auc_score(y_val, y_val_proba) if y_val_proba is not None else None\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"BestParams\": grid.best_params_,\n",
    "        \"Val Accuracy\": val_acc,\n",
    "        \"Val ROC-AUC\": val_auc\n",
    "    })\n",
    "\n",
    "# ============================================================\n",
    "# RÉSULTATS ET SÉLECTION DU MEILLEUR MODÈLE\n",
    "# ============================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n Résumé des performances sur le jeu de validation :\")\n",
    "print(results_df)\n",
    "\n",
    "best_model_name = results_df.sort_values(by=\"Val ROC-AUC\", ascending=False).iloc[0][\"Model\"]\n",
    "final_model = best_models[best_model_name]\n",
    "\n",
    "joblib.dump(final_model, r\"C:\\Users\\HP\\course\\phase_5\\Models\\Best_Model_Deployment.pkl\")\n",
    "print(f\"\\n Meilleur modèle sélectionné : {best_model_name} sauvegardé pour le déploiement !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a22cd-4f3d-46f3-b275-00db832e246c",
   "metadata": {},
   "source": [
    "Le modèle XGBoost a été retenu comme modèle final de prédiction du churn client.\n",
    "Il combine un excellent compromis entre performance, robustesse et capacité de généralisation.\n",
    "Ce modèle sera donc sauvegardé et déployé dans l’application Streamlit pour la phase de prédiction en temps réel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
