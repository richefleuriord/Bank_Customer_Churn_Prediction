{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b0d340-fa4a-4001-a858-41e406f3c440",
   "metadata": {},
   "source": [
    "  # **AKADEMI EDUCATION**\n",
    "# **Première cohorte (2025): Science des données et intelligence artificielle**\n",
    "#### *Phase 5: PROJET DE SCIENCE DES DONNÉES*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a1f0e-0e5f-4c2b-8c1c-00660bb3d88c",
   "metadata": {},
   "source": [
    "**Noms des étudiants du groupe: Riché FLEURINORD et Micka LOUIS**   \n",
    "**Rythme d’apprentissage: Autonome**  \n",
    "**Date de soutenance: 27 octobre 2025**  \n",
    "**Noms des instructeurs: Wedter JEROME et Geovany Batista Polo LAGUERRE**  \n",
    "**Lien de l’article de blog (lien du dépôt GitHub): https://github.com/richefleuriord/Bank_Customer_Churn_Prediction.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9508467-8365-49cd-b508-53c98ce472d6",
   "metadata": {},
   "source": [
    "# *3-Préparation des données*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf1445-d417-40b3-9493-79b892fcd2d4",
   "metadata": {},
   "source": [
    "## Introduction et Objectifs de la Préparation des Données\n",
    "\n",
    "La **préparation des données** est une étape essentielle dans tout projet de *Data Science*.  \n",
    "Elle consiste à transformer le jeu de données brut en un format propre, cohérent et exploitable pour la modélisation prédictive.  \n",
    "\n",
    "Dans ce projet, l’objectif principal est de **préparer le jeu de données des clients bancaires** afin de construire un modèle capable de prédire le **risque de départ (churn)** des clients.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs spécifiques\n",
    "\n",
    "- Nettoyer les données et vérifier leur cohérence.  \n",
    "- Créer de nouvelles variables pertinentes à partir des variables existantes (*feature engineering*).  \n",
    "- Transformer les variables catégorielles en variables numériques exploitables par les algorithmes de *Machine Learning*.  \n",
    "- Normaliser les variables numériques afin d’éviter les effets de différence d’échelle.  \n",
    "- Gérer le déséquilibre de la variable cible (**Exited**) à l’aide de la méthode **SMOTE** (*Synthetic Minority Oversampling Technique*).  \n",
    "- Séparer les données en trois ensembles distincts :  \n",
    "  - **Train (70%)** : pour l’apprentissage du modèle.  \n",
    "  - **Validation (15%)** : pour l’ajustement des hyperparamètres.  \n",
    "  - **Test (15%)** : pour l’évaluation finale des performances.\n",
    "\n",
    "---\n",
    "\n",
    "### Étapes principales du pipeline de préparation\n",
    "\n",
    "1. **Vérifications de base**: identification des valeurs manquantes, doublons et vérification de la cohérence de la variable cible.  \n",
    "2. **Feature Engineering**: suppression de variables non pertinentes, création de nouvelles variables (ratios, groupes d’âge, interactions, etc.).  \n",
    "3. **Encodage** des variables catégorielles à l’aide du *One-Hot Encoding*.  \n",
    "4. **Normalisation** des variables numériques à l’aide du `StandardScaler`.  \n",
    "5. **Équilibrage des classes** avec **SMOTE** pour corriger le déséquilibre de la variable cible.  \n",
    "6. **Séparation finale** du jeu de données en ensembles d’entraînement, de validation et de test.  \n",
    "7. **Sauvegarde** des jeux de données préparés pour la phase de modélisation.\n",
    "\n",
    "---\n",
    "\n",
    "*Cette étape garantit la qualité et la fiabilité du jeu de données, condition essentielle pour la performance du modèle prédictif.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad55167-a96d-4dd3-be6b-f4a72d0ad962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes totales: 0\n",
      "Doublons : 0\n",
      "\n",
      "Répartition de la cible:\n",
      "Exited\n",
      "0    79.62\n",
      "1    20.38\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Avant SMOTE :\n",
      "Exited\n",
      "0    5573\n",
      "1    1427\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Après SMOTE :\n",
      "Exited\n",
      "0    5573\n",
      "1    5573\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Données prêtes pour la modélisation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Étapes : nettoyage, feature engineering, encodage, normalisation, SMOTE\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ============================================================\n",
    "# CHARGEMENT DU JEU DE DONNÉES\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../Data/Customer-Churn-Records.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# VÉRIFICATIONS DE BASE\n",
    "# ============================================================\n",
    "print(\"Valeurs manquantes totales:\", df.isnull().sum().sum())\n",
    "print(\"Doublons :\", df.duplicated().sum())\n",
    "print(\"\\nRépartition de la cible:\")\n",
    "print(df['Exited'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "# Suppression des colonnes non pertinentes\n",
    "df = df.drop(columns=[\"CustomerId\", \"RowNumber\", \"Surname\"], errors='ignore')\n",
    "\n",
    "# Suppression de la variable qui fuit la cible\n",
    "df = df.drop(columns=[\"Complain\"], errors='ignore')\n",
    "\n",
    "# Ratio Balance / Salary\n",
    "df['BalanceToSalaryRatio'] = df['Balance'] / (df['EstimatedSalary'] + 1)\n",
    "\n",
    "# Création de groupes d'âge\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[17, 25, 35, 50, 65, 100],\n",
    "                        labels=['18-25', '26-35', '36-50', '51-65', '65+'])\n",
    "\n",
    "# Interaction entre certaines variables\n",
    "df['ActiveCredit'] = df['IsActiveMember'] * df['HasCrCard']\n",
    "\n",
    "# Variable indicatrice : faible satisfaction\n",
    "df['LowSatisfaction'] = (df['Satisfaction Score'] <= 2).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# ENCODAGE DES VARIABLES CATÉGORIELLES\n",
    "# ============================================================\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# ============================================================\n",
    "# NORMALISATION DES VARIABLES NUMÉRIQUES\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "num_features = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                'NumOfProducts', 'BalanceToSalaryRatio']\n",
    "\n",
    "df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "# ============================================================\n",
    "# SÉPARATION FEATURES / CIBLE\n",
    "# ============================================================\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# ============================================================\n",
    "# SPLIT TRAIN / VAL / TEST\n",
    "# ============================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# ALIGNEMENT DES COLONNES (au cas où certaines dummies manqueraient)\n",
    "# ============================================================\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# ============================================================\n",
    "# INSPECTION DE LA RÉPARTITION AVANT SMOTE\n",
    "# ============================================================\n",
    "print(\"\\nAvant SMOTE :\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# ============================================================\n",
    "# ÉQUILIBRAGE DES CLASSES AVEC SMOTE\n",
    "# ============================================================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nAprès SMOTE :\")\n",
    "print(y_train_res.value_counts())\n",
    "\n",
    "# ============================================================\n",
    "# SAUVEGARDE DES JEUX DE DONNÉES PRÉPARÉS\n",
    "# ============================================================\n",
    "X_train_res.to_csv(\"../Data/X_train_prepared.csv\", index=False)\n",
    "y_train_res.to_csv(\"../Data/y_train_prepared.csv\", index=False)\n",
    "X_val.to_csv(\"../Data/X_val_prepared.csv\", index=False)\n",
    "y_val.to_csv(\"../Data/y_val_prepared.csv\", index=False)\n",
    "X_test.to_csv(\"../Data/X_test_prepared.csv\", index=False)\n",
    "y_test.to_csv(\"../Data/y_test_prepared.csv\", index=False)\n",
    "\n",
    "print(\"\\nDonnées prêtes pour la modélisation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
