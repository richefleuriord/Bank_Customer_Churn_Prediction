{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b0d340-fa4a-4001-a858-41e406f3c440",
   "metadata": {},
   "source": [
    "  # **AKADEMI EDUCATION**\n",
    "# **Première cohorte (2025): Science des données et intelligence artificielle**\n",
    "#### *Phase 5: PROJET DE SCIENCE DES DONNÉES*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a1f0e-0e5f-4c2b-8c1c-00660bb3d88c",
   "metadata": {},
   "source": [
    "**Noms des étudiants du groupe: Riché FLEURINORD et Micka LOUIS**   \n",
    "**Rythme d’apprentissage: Autonome**  \n",
    "**Date de soutenance: 27 octobre 2025**  \n",
    "**Noms des instructeurs: Wedter JEROME et Geovany Batista Polo LAGUERRE**  \n",
    "**Lien de l’article de blog (lien du dépôt GitHub): https://github.com/richefleuriord/Bank_Customer_Churn_Prediction.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9508467-8365-49cd-b508-53c98ce472d6",
   "metadata": {},
   "source": [
    "# *3-Préparation des données*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf1445-d417-40b3-9493-79b892fcd2d4",
   "metadata": {},
   "source": [
    "## Préparation Complète des Données\n",
    "\n",
    "La **préparation des données** constitue une étape essentielle du projet, garantissant la qualité, la cohérence et la pertinence du jeu de données avant la modélisation.  \n",
    "Cette section détaille le processus complet appliqué au dataset de churn bancaire afin d’obtenir une base exploitable pour les modèles prédictifs.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectif général\n",
    "\n",
    "Transformer le jeu de données brut en un ensemble propre, cohérent et prêt pour la modélisation, tout en assurant la reproductibilité et la compatibilité avec le futur déploiement de l’application Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "### Étapes principales\n",
    "\n",
    "1. **Chargement et vérifications initiales**  \n",
    "   - Import du jeu de données depuis le répertoire `../Data/Customer-Churn-Records.csv`.  \n",
    "   - Vérification du nombre de lignes, colonnes, doublons et valeurs manquantes.  \n",
    "   - Analyse de la distribution de la variable cible `Exited` pour évaluer le déséquilibre de classes.\n",
    "\n",
    "2. **Nettoyage et Feature Engineering**  \n",
    "   - Suppression des colonnes non pertinentes: `CustomerId`, `RowNumber`, `Surname`, `Complain`.  \n",
    "   - Création de nouvelles variables dérivées:\n",
    "     - `BalanceToSalaryRatio` : rapport entre le solde et le salaire estimé.  \n",
    "     - `AgeCategory` : segmentation des clients en catégories — *Jeune*, *Moyen* et *Âgé*.  \n",
    "     - `NumOfProductsBinary` : codage binaire du nombre de produits détenus (0 si un seul, 1 si plusieurs).  \n",
    "     - `ActiveCredit` : interaction entre la carte de crédit et l’activité du client.  \n",
    "     - `LowSatisfaction` : indicateur des clients insatisfaits (score ≤ 2).  \n",
    "\n",
    "3. **Encodage des variables catégorielles**  \n",
    "   - Application d’un **OrdinalEncoder** sur les variables ordinales: `Card Type`, `AgeCategory`.  \n",
    "   - Application d’un **OneHotEncoder** sur les variables nominales: `Gender`, `Geography` (avec suppression d’une modalité pour éviter la colinéarité).  \n",
    "   - Les variables numériques sont conservées sans transformation.\n",
    "\n",
    "4. **Séparation du jeu de données**  \n",
    "   - Division en trois sous-ensembles:  \n",
    "     - **Train (70%)** : apprentissage du modèle.  \n",
    "     - **Validation (15%)** : ajustement des hyperparamètres.  \n",
    "     - **Test (15%)** : évaluation finale.  \n",
    "   - Utilisation du paramètre `stratify=y` pour conserver la proportion de classes dans chaque sous-ensemble.\n",
    "\n",
    "5. **Transformation et assemblage final**  \n",
    "   - Application du `ColumnTransformer` pour combiner les encodages.  \n",
    "   - Récupération des noms de colonnes issus des transformations pour garantir la compatibilité des modèles.  \n",
    "   - Construction de `DataFrames` propres et alignés : `X_train`, `X_val`, `X_test`.\n",
    "\n",
    "6. **Sauvegarde et traçabilité**  \n",
    "   - Enregistrement des fichiers préparés (`X_train_prepared.csv`, `y_train_prepared.csv`, etc.).  \n",
    "   - Sauvegarde des colonnes finales encodées dans `columns_final.pkl` afin d’assurer la reproductibilité et le déploiement cohérent du pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé des points clés\n",
    "\n",
    "| Étape | Objectif | Outils utilisés |\n",
    "|:------|:----------|:----------------|\n",
    "| Chargement | Importation et vérification du dataset | `pandas` |\n",
    "| Nettoyage | Suppression des colonnes inutiles, création de ratios | `numpy`, `pandas` |\n",
    "| Feature Engineering | Ajout de variables explicatives pertinentes | `pandas` |\n",
    "| Encodage | Transformation catégorielle (ordinal + one-hot) | `sklearn.preprocessing` |\n",
    "| Split des données | Constitution des ensembles train/val/test | `train_test_split` |\n",
    "| Sauvegarde | Export des objets pour modélisation et déploiement | `joblib`, `csv` |\n",
    "\n",
    "---\n",
    "\n",
    "*Cette préparation rigoureuse garantit la qualité du pipeline analytique, renforce la robustesse des modèles et facilite l’intégration fluide dans la phase de modélisation et de déploiement Streamlit.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad55167-a96d-4dd3-be6b-f4a72d0ad962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement réussi : 10000 lignes, 18 colonnes\n",
      "\n",
      "--- Vérifications de base ---\n",
      "Valeurs manquantes : 0\n",
      "Doublons : 0\n",
      "Distribution Exited :\n",
      " Exited\n",
      "0    79.62\n",
      "1    20.38\n",
      "Name: proportion, dtype: float64\n",
      "Préparation complète des données terminée\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PRÉPARATION COMPLÈTE DES DONNÉES (CORRIGÉE ET COMPLÈTE)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# CHARGEMENT DES DONNÉES\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"../Data/Customer-Churn-Records.csv\")\n",
    "print(f\"Chargement réussi : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "\n",
    "# ============================================================\n",
    "# VÉRIFICATIONS DE BASE\n",
    "# ============================================================\n",
    "print(\"\\n--- Vérifications de base ---\")\n",
    "print(\"Valeurs manquantes :\", df.isnull().sum().sum())\n",
    "print(\"Doublons :\", df.duplicated().sum())\n",
    "print(\"Distribution Exited :\\n\", df['Exited'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "# Suppression des colonnes non pertinentes\n",
    "df = df.drop(columns=[\"CustomerId\", \"RowNumber\", \"Surname\", \"Complain\"], errors='ignore')\n",
    "\n",
    "# Ratio Balance / Salaire\n",
    "df['BalanceToSalaryRatio'] = df['Balance'] / (df['EstimatedSalary'] + 1)\n",
    "\n",
    "# Catégorisation âge\n",
    "df['AgeCategory'] = pd.cut(\n",
    "    df['Age'], bins=[17, 35, 55, 100],\n",
    "    labels=['Jeune', 'Moyen', 'Âgé']\n",
    ")\n",
    "df = df.drop(columns=['Age'], errors='ignore')\n",
    "\n",
    "# Codage binaire du nombre de produits : 0 si 1 produit, 1 si 2 ou plus\n",
    "df['NumOfProductsBinary'] = np.where(df['NumOfProducts'] == 1, 0, 1)\n",
    "df = df.drop(columns=['NumOfProducts'], errors='ignore')\n",
    "\n",
    "# Variables combinées et binaires\n",
    "df['ActiveCredit'] = df['IsActiveMember'] * df['HasCrCard']\n",
    "df['LowSatisfaction'] = (df['Satisfaction Score'] <= 2).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# ENCODAGE DES VARIABLES CATÉGORIELLES\n",
    "# ============================================================\n",
    "\n",
    "# Variables ordinales et nominales\n",
    "ordinal_cols = ['Card Type', 'AgeCategory']\n",
    "nominal_cols = ['Gender', 'Geography']\n",
    "\n",
    "# ColumnTransformer pour encodage\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('ord', OrdinalEncoder(), ordinal_cols),\n",
    "    ('nom', OneHotEncoder(drop='first', sparse=False), nominal_cols)\n",
    "], remainder='passthrough')  # les colonnes numériques restent intactes\n",
    "\n",
    "# ============================================================\n",
    "# SÉPARATION FEATURES / TARGET\n",
    "# ============================================================\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# ============================================================\n",
    "# SPLIT TRAIN / VAL / TEST\n",
    "# ============================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TRANSFORMATION DES COLONNES CATÉGORIELLES\n",
    "# ============================================================\n",
    "\n",
    "# Transformation\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Récupération des noms des colonnes (compatible toutes versions)\n",
    "ord_names = ordinal_cols\n",
    "try:\n",
    "    nom_names = preprocessor.named_transformers_['nom'].get_feature_names_out(nominal_cols)\n",
    "except AttributeError:\n",
    "    nom_names = preprocessor.named_transformers_['nom'].get_feature_names(nominal_cols)\n",
    "\n",
    "num_names = [col for col in X_train.columns if col not in ordinal_cols + nominal_cols]\n",
    "all_columns = list(ord_names) + list(nom_names) + list(num_names)\n",
    "\n",
    "# Construction des DataFrames finaux\n",
    "X_train = pd.DataFrame(X_train_transformed, columns=all_columns)\n",
    "X_val = pd.DataFrame(X_val_transformed, columns=all_columns)\n",
    "X_test = pd.DataFrame(X_test_transformed, columns=all_columns)\n",
    "\n",
    "# ============================================================\n",
    "# SAUVEGARDE DES COLONNES FINALES POUR LE DÉPLOIEMENT\n",
    "# ============================================================\n",
    "joblib.dump(list(X_train.columns), r\"C:\\Users\\HP\\course\\phase_5\\Models\\columns_final.pkl\")\n",
    "\n",
    "# ============================================================\n",
    "# SAUVEGARDE DES DONNÉES PRÉPARÉES\n",
    "# ============================================================\n",
    "X_train.to_csv(\"../Data/X_train_prepared.csv\", index=False)\n",
    "y_train.to_csv(\"../Data/y_train_prepared.csv\", index=False)\n",
    "X_val.to_csv(\"../Data/X_val_prepared.csv\", index=False)\n",
    "y_val.to_csv(\"../Data/y_val_prepared.csv\", index=False)\n",
    "X_test.to_csv(\"../Data/X_test_prepared.csv\", index=False)\n",
    "y_test.to_csv(\"../Data/y_test_prepared.csv\", index=False)\n",
    "\n",
    "print(\"Préparation complète des données terminée\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
