  # **AKADEMI EDUCATION**
# **PremiÃ¨re cohorte (2025): Science des donnÃ©es et intelligence artificielle**
#### *Phase 5: PROJET DE SCIENCE DES DONNÃ‰ES*
**Noms des Ã©tudiants du groupe: RichÃ© FLEURINORD et Micka LOUIS**   
**Rythme dâ€™apprentissage: Autonome**  
**Date de soutenance: 27 octobre 2025**  
**Noms des instructeurs: Wedter JEROME et Geovany Batista Polo LAGUERRE**  
**Lien de lâ€™article de blog (lien du dÃ©pÃ´t GitHub): https://github.com/richefleuriord/Bank_Customer_Churn_Prediction.git**

# PrÃ©diction du Churn Client Bancaire Ã  lâ€™aide du Machine Learning

![BanniÃ¨re aviation](images/imag1.jpeg)

## 1. Vue dâ€™ensemble du projet
Ce projet de Data Science a pour objectif de prÃ©dire le **churn des clients bancaires**, câ€™est-Ã -dire identifier les clients susceptibles de quitter la banque.  
Lâ€™approche adoptÃ©e combine **prÃ©paration des donnÃ©es**, **modÃ©lisation prÃ©dictive**, **Ã©valuation rigoureuse**, **dÃ©ploiement en temps rÃ©el**, et **explicabilitÃ© du modÃ¨le**, permettant de fournir aux dÃ©cideurs des insights fiables et actionnables pour la **fidÃ©lisation client**.

---

## 2. ComprÃ©hension du problÃ¨me mÃ©tier

![BanniÃ¨re aviation](images/imag2.jpeg)

La fidÃ©lisation des clients est essentielle pour maintenir la rentabilitÃ© et la stabilitÃ© dâ€™une institution bancaire.  
Le churn peut entraÃ®ner des pertes financiÃ¨res significatives et affecter la rÃ©putation de la banque.  
Le projet vise Ã  :

- Identifier les clients Ã  risque de dÃ©part.
- Comprendre les facteurs influenÃ§ant le churn.
- Fournir un outil prÃ©dictif utilisable par les Ã©quipes marketing et la direction.

---

## 3. ComprÃ©hension des donnÃ©es
Le jeu de donnÃ©es contient des informations sur les clients bancaires, incluant :

- CaractÃ©ristiques dÃ©mographiques : Ã¢ge, genre, pays.
- DonnÃ©es financiÃ¨res : solde, revenu estimÃ©, score de crÃ©dit.
- Informations sur les produits dÃ©tenus et lâ€™activitÃ© bancaire.
- Indicateurs de satisfaction et de fidÃ©litÃ©.

![BanniÃ¨re aviation](images/plot1.png)

**PrÃ©paration des donnÃ©es :**

- SÃ©paration en jeux Train (70%), Validation (15%) et Test (15%).
- Nettoyage, normalisation et encodage.
- Gestion du dÃ©sÃ©quilibre de classes via SMOTE et pondÃ©ration selon le modÃ¨le.

![BanniÃ¨re aviation](images/prep1.jpeg)

---

## 4. Profiling des clients
Un **profil dÃ©taillÃ© des clients** a Ã©tÃ© Ã©tabli pour comprendre les comportements :

- CatÃ©gories dâ€™Ã¢ge (Jeune, Moyen, Ã‚gÃ©)
- Nombre de produits dÃ©tenus
- ActivitÃ© et engagement dans les opÃ©rations bancaires
- Score de satisfaction et points de fidÃ©litÃ©

Cette segmentation a permis de mieux interprÃ©ter les prÃ©dictions et de guider les stratÃ©gies de fidÃ©lisation.

---

## 5. Analyse exploratoire (EDA)
Lâ€™EDA a permis de visualiser et comprendre les relations entre les variables :

- RÃ©partition des clients par Ã¢ge, genre et pays.
- CorrÃ©lations entre solde, revenu, anciennetÃ© et churn.
- Analyse des variables clÃ©s : nombre de produits, activitÃ©, score de satisfaction.
- Identification des patterns et insights exploitables pour la modÃ©lisation.

![BanniÃ¨re aviation](images/plot5.jpeg)

![BanniÃ¨re aviation](images/Gender&NumOfProduct.jpeg)

---

## 6. ModÃ©lisation
**Algorithmes utilisÃ©s :**

- RÃ©gression Logistique
- ForÃªt AlÃ©atoire (Random Forest)
- XGBoost
- RÃ©seau de Neurones (MLP)

**Ã‰tapes principales :**

1. Chargement des donnÃ©es prÃ©parÃ©es.
2. DÃ©finition des pipelines (scaling, SMOTE, pondÃ©ration).
3. Optimisation via GridSearchCV.
4. Ã‰valuation sur le jeu de validation (Accuracy, ROC-AUC, F1-score).
5. SÃ©lection du meilleur modÃ¨le (XGBoost retenu).

**Performances clÃ©s :**

| ModÃ¨le               | ROC-AUC CV  | Accuracy Validation |
|----------------------|------------|------------------|
| Logistic Regression  | 0.7603     | 69.5%            |
| Random Forest        | 0.7892     | 76.3%            |
| XGBoost              | 0.7996     | 72.7%            |
| Neural Network (MLP) | 0.7622     | 79.3%            |


![BanniÃ¨re aviation](images/plot8.jpeg)

Le **XGBoost** a Ã©tÃ© sÃ©lectionnÃ© pour son compromis optimal entre **performance, robustesse et gÃ©nÃ©ralisation**.

---

## 7. Ã‰valuation
**MÃ©thodologie :**

- Ã‰valuation sur validation et test.
- Utilisation de mÃ©triques adaptÃ©es au dÃ©sÃ©quilibre des classes :  
  Accuracy, Precision, Recall, F1-score, ROC-AUC, Matrice de confusion.

**RÃ©sultats :**

- ROC-AUC sur test : 0.878
- Accuracy sur test : 85.6%
- Recall pour la classe minoritaire : 0.45

![BanniÃ¨re aviation](images/plot10.jpeg)

![BanniÃ¨re aviation](images/plot9.jpeg)

Le modÃ¨le XGBoost dÃ©montre une **excellente capacitÃ© Ã  prÃ©dire le churn** tout en maintenant un bon Ã©quilibre entre prÃ©cision et couverture.

---

## 8. DÃ©ploiement
Le modÃ¨le XGBoost a Ã©tÃ© intÃ©grÃ© dans une **application web interactive Streamlit** permettant :

- Saisie des caractÃ©ristiques clients.
- PrÃ©diction instantanÃ©e de la probabilitÃ© de churn.
- Visualisation intuitive des rÃ©sultats (% dÃ©part / % fidÃ©litÃ©).
- InterprÃ©tation stratÃ©gique pour guider les actions commerciales.

**Fichiers clÃ©s :**

- `Best_Model_Deployment.pkl` : pipeline complet (prÃ©traitement + modÃ¨le).
- `columns_final.pkl` : colonnes finales utilisÃ©es pour lâ€™entraÃ®nement.

**Exemple de prÃ©diction :**

![BanniÃ¨re aviation](images/plot13.jpeg)

![BanniÃ¨re aviation](images/plot12.jpeg)

![BanniÃ¨re aviation](images/plot11.jpeg)

- Client jeune, France, 1 produit, score de satisfaction moyen : risque de dÃ©part 34.38%
- Client Ã¢gÃ©, Allemagne, 3 produits, score de satisfaction Ã©levÃ© : risque de dÃ©part 10.13%
- Cliente moyenne, Espagne, 1 produit, score de satisfaction faible : risque de dÃ©part 53.53%

---

## 9. ExplicabilitÃ© du modÃ¨le
**Objectif :** comprendre comment le modÃ¨le prend ses dÃ©cisions pour rendre les prÃ©dictions transparentes et actionnables.

**Outils :**

- **SHAP** : explication globale et locale.
- **LIME** : interprÃ©tation client par client.
- **Feature Importance** : impact moyen des variables sur le modÃ¨le.

**Insights clÃ©s :**

![BanniÃ¨re aviation](images/explicabilite1.png)

![BanniÃ¨re aviation](images/explicabilite2.png)

![BanniÃ¨re aviation](images/explicabilite3.png)

- AgeCategory, NumOfProductsBinary et IsActiveMember sont les facteurs les plus influents.
- Les variables Ã©conomiques (solde, salaire, BalanceToSalaryRatio) modÃ¨rent les prÃ©dictions.
- Analyse locale permet de cibler les actions de fidÃ©lisation pour chaque client.

---

## 10. Recommandations mÃ©tiers
1. **Suivi et monitoring** : surveiller les performances du modÃ¨le et dÃ©tecter la dÃ©rive des donnÃ©es.
2. **Actualisation des donnÃ©es** : intÃ©grer de nouvelles sources et mettre Ã  jour rÃ©guliÃ¨rement les features.
3. **Optimisation des modÃ¨les** : tester XGBoost, LightGBM, rÃ©seaux de neurones, ou solutions AutoML.
4. **Automatisation de la fidÃ©lisation** : intÃ©gration CRM pour campagnes ciblÃ©es.
5. **Renforcement de lâ€™explicabilitÃ©** : usage continu de SHAP et LIME pour justifier les dÃ©cisions.
6. **Extension Ã  dâ€™autres domaines** : prÃ©diction de dÃ©faut, segmentation dynamique, portefeuille client.

---

## 11. Conclusion
Le projet XGBoost a permis de construire un **modÃ¨le prÃ©dictif robuste, interprÃ©table et opÃ©rationnel**, capable dâ€™anticiper le churn avec fiabilitÃ©.  
GrÃ¢ce Ã  son dÃ©ploiement via Streamlit, la banque dispose dÃ©sormais dâ€™un outil pratique pour **optimiser la fidÃ©lisation client et la stratÃ©gie commerciale**.

---

## 12. Ã‰tapes suivantes
- **Monitoring continu** du modÃ¨le et dÃ©tection de la dÃ©rive.
- **Mise Ã  jour rÃ©guliÃ¨re** des donnÃ©es et des features.
- **Exploration de modÃ¨les hybrides et AutoML** pour amÃ©liorer la performance.
- **IntÃ©gration opÃ©rationnelle** dans les systÃ¨mes CRM pour actions automatisÃ©es.
- **Analyse continue de lâ€™explicabilitÃ©** pour renforcer la confiance des Ã©quipes.

---
 
Bank_Customer_Churn_Prediction/  
â”‚
â”œâ”€â”€ ğŸ“ Data/ # Contient les donnÃ©es brutes et transformÃ©es  
â”‚ â”œâ”€â”€ Customer-Churn-Records.csv # Jeu de donnÃ©es brut initial  
â”‚ â”œâ”€â”€ X_train_prepared # Variables explicatives du jeu d'entraÃ®nement  
â”‚ â”œâ”€â”€ X_val_prepared # Variables explicatives du jeu de validation  
â”‚ â”œâ”€â”€ X_test_prepared # Variables explicatives du jeu de test  
â”‚ â”œâ”€â”€ y_train_prepared # Variable cible (churn ou non) du jeu d'entraÃ®nement  
â”‚ â”œâ”€â”€ y_val_prepared # Variable cible du jeu de validation  
â”‚ â”œâ”€â”€ y_test_prepared # Variable cible du jeu de test  
â”‚
â”œâ”€â”€ ğŸ“ les_Notebooks_du_Projet/ # Tous les notebooks Jupyter (profiling, EDA, modÃ©lisation, etc.)  
â”‚ â”œâ”€â”€ 01_Profiling_des_clients.ipynb  
â”‚ â”œâ”€â”€ 02_EDA.ipynb  
â”‚ â”œâ”€â”€ 03_Modelisation.ipynb  
â”‚ â”œâ”€â”€ 04_Evaluation.ipynb  
â”‚ â”œâ”€â”€ 05_Explicabilite.ipynb  
â”‚ â”œâ”€â”€ 06_Deploiement.ipynb   
â”‚
â”œâ”€â”€ ğŸ“ Models/ # Sauvegarde des modÃ¨les entraÃ®nÃ©s (.pkl, .joblib)  
â”‚ â”œâ”€â”€ Best_Model_Deployment.pkl  
â”‚ â”œâ”€â”€ columns_final.pkl  
â”‚
â”œâ”€â”€ ğŸ“ Outputs/ # Rapports, figures et notebooks exportÃ©s en PDF  
â”‚ â”œâ”€â”€ EDA_Complet.pdf  
â”‚ â”œâ”€â”€ Evaluation_Report.pdf  
â”‚ â”œâ”€â”€ Demonstration_deploiement_Streamlit.pdf  
â”‚ â”œâ”€â”€ Demonstration_deploiement_Streamlit2.pdf  
â”‚ â”œâ”€â”€ Demonstration_deploiement_Streamlit3.pdf  
â”‚
â”œâ”€â”€ ğŸ“ Streamlit/ # Code de lâ€™application web Streamlit  
â”‚ â”œâ”€â”€ app.py  
â”‚ â”œâ”€â”€ config.json  
â”‚
â”œâ”€â”€ ğŸ“ images/ # Graphiques, visuels et banniÃ¨res pour le README  
â”‚ â”œâ”€â”€ plot.png   
â”‚ â”œâ”€â”€ Autres plots   
â”‚
â”œâ”€â”€ ğŸ“ anaconda_projects/db/ # Environnement Anaconda / base locale  
â”‚
â”œâ”€â”€ ğŸ“œ Mini_Document_de_Cadrage.pdf # Note de cadrage du projet   
â”œâ”€â”€ ğŸ“œ Proposition_de_Projet_Capstone.pdf  
â”œâ”€â”€ ğŸ“œ LICENSE # Type de licence (MIT)   
â”œâ”€â”€ ğŸ“œ README.md # Documentation principale du projet  
â””â”€â”€ ğŸ“œ requirements.txt # Liste des dÃ©pendances Python Ã  installer  
---

*Analyse rÃ©alisÃ©e par RichÃ© Fleurinord et Micka Louis â€” Phase 5 : Projet Data Science & IA (Akademi)*    
Â© 2025 â€” PrÃ©diction du Churn Client avec XGBoost   
