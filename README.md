  # **AKADEMI EDUCATION**
# **Premi√®re cohorte (2025): Science des donn√©es et intelligence artificielle**
#### *Phase 5: PROJET DE SCIENCE DES DONN√âES*
**Noms des √©tudiants du groupe: Rich√© FLEURINORD et Micka LOUIS**   
**Rythme d‚Äôapprentissage: Autonome**  
**Date de soutenance: 27 octobre 2025**  
**Noms des instructeurs: Wedter JEROME et Geovany Batista Polo LAGUERRE**  
**Lien de l‚Äôarticle de blog (lien du d√©p√¥t GitHub): https://github.com/richefleuriord/Bank_Customer_Churn_Prediction.git**

# Pr√©diction du Churn Client Bancaire √† l‚Äôaide du Machine Learning

![Banni√®re aviation](../images/imag1.jpeg)

## 1. Vue d‚Äôensemble du projet
Ce projet de Data Science a pour objectif de pr√©dire le **churn des clients bancaires**, c‚Äôest-√†-dire identifier les clients susceptibles de quitter la banque.  
L‚Äôapproche adopt√©e combine **pr√©paration des donn√©es**, **mod√©lisation pr√©dictive**, **√©valuation rigoureuse**, **d√©ploiement en temps r√©el**, et **explicabilit√© du mod√®le**, permettant de fournir aux d√©cideurs des insights fiables et actionnables pour la **fid√©lisation client**.

---

## 2. Compr√©hension du probl√®me m√©tier

![Banni√®re aviation](../images/imag2.jpeg)

La fid√©lisation des clients est essentielle pour maintenir la rentabilit√© et la stabilit√© d‚Äôune institution bancaire.  
Le churn peut entra√Æner des pertes financi√®res significatives et affecter la r√©putation de la banque.  
Le projet vise √† :

- Identifier les clients √† risque de d√©part.
- Comprendre les facteurs influen√ßant le churn.
- Fournir un outil pr√©dictif utilisable par les √©quipes marketing et la direction.

---

## 3. Compr√©hension des donn√©es
Le jeu de donn√©es contient des informations sur les clients bancaires, incluant :

- Caract√©ristiques d√©mographiques : √¢ge, genre, pays.
- Donn√©es financi√®res : solde, revenu estim√©, score de cr√©dit.
- Informations sur les produits d√©tenus et l‚Äôactivit√© bancaire.
- Indicateurs de satisfaction et de fid√©lit√©.

![Banni√®re aviation](../images/imag4.jpg)

**Pr√©paration des donn√©es :**

- S√©paration en jeux Train (70%), Validation (15%) et Test (15%).
- Nettoyage, normalisation et encodage.
- Gestion du d√©s√©quilibre de classes via SMOTE et pond√©ration selon le mod√®le.

---

## 4. Profiling des clients
Un **profil d√©taill√© des clients** a √©t√© √©tabli pour comprendre les comportements :

- Cat√©gories d‚Äô√¢ge (Jeune, Moyen, √Çg√©)
- Nombre de produits d√©tenus
- Activit√© et engagement dans les op√©rations bancaires
- Score de satisfaction et points de fid√©lit√©

Cette segmentation a permis de mieux interpr√©ter les pr√©dictions et de guider les strat√©gies de fid√©lisation.

---

## 5. Analyse exploratoire (EDA)
L‚ÄôEDA a permis de visualiser et comprendre les relations entre les variables :

- R√©partition des clients par √¢ge, genre et pays.
- Corr√©lations entre solde, revenu, anciennet√© et churn.
- Analyse des variables cl√©s : nombre de produits, activit√©, score de satisfaction.
- Identification des patterns et insights exploitables pour la mod√©lisation.

![Banni√®re aviation](../images/plot1.png)

![Banni√®re aviation](../images/imag4.jpg)
---

## 6. Mod√©lisation
**Algorithmes utilis√©s :**

- R√©gression Logistique
- For√™t Al√©atoire (Random Forest)
- XGBoost
- R√©seau de Neurones (MLP)

**√âtapes principales :**

1. Chargement des donn√©es pr√©par√©es.
2. D√©finition des pipelines (scaling, SMOTE, pond√©ration).
3. Optimisation via GridSearchCV.
4. √âvaluation sur le jeu de validation (Accuracy, ROC-AUC, F1-score).
5. S√©lection du meilleur mod√®le (XGBoost retenu).

**Performances cl√©s :**

| Mod√®le               | ROC-AUC CV  | Accuracy Validation |
|----------------------|------------|------------------|
| Logistic Regression  | 0.7603     | 69.5%            |
| Random Forest        | 0.7892     | 76.3%            |
| XGBoost              | 0.7996     | 72.7%            |
| Neural Network (MLP) | 0.7622     | 79.3%            |

Le **XGBoost** a √©t√© s√©lectionn√© pour son compromis optimal entre **performance, robustesse et g√©n√©ralisation**.

---

## 7. üìà √âvaluation
**M√©thodologie :**

- √âvaluation sur validation et test.
- Utilisation de m√©triques adapt√©es au d√©s√©quilibre des classes :  
  Accuracy, Precision, Recall, F1-score, ROC-AUC, Matrice de confusion.

**R√©sultats :**

- ROC-AUC sur test : 0.878
- Accuracy sur test : 85.6%
- Recall pour la classe minoritaire : 0.45

Le mod√®le XGBoost d√©montre une **excellente capacit√© √† pr√©dire le churn** tout en maintenant un bon √©quilibre entre pr√©cision et couverture.

---

## 8. D√©ploiement
Le mod√®le XGBoost a √©t√© int√©gr√© dans une **application web interactive Streamlit** permettant :

- Saisie des caract√©ristiques clients.
- Pr√©diction instantan√©e de la probabilit√© de churn.
- Visualisation intuitive des r√©sultats (% d√©part / % fid√©lit√©).
- Interpr√©tation strat√©gique pour guider les actions commerciales.

**Fichiers cl√©s :**

- `Best_Model_Deployment.pkl` : pipeline complet (pr√©traitement + mod√®le).
- `columns_final.pkl` : colonnes finales utilis√©es pour l‚Äôentra√Ænement.

**Exemple de pr√©diction :**

- Client jeune, France, 1 produit, score de satisfaction moyen : risque de d√©part 34.38%
- Client √¢g√©, Allemagne, 3 produits, score de satisfaction √©lev√© : risque de d√©part 10.13%
- Cliente moyenne, Espagne, 1 produit, score de satisfaction faible : risque de d√©part 53.53%

---

## 9. üß© Explicabilit√© du mod√®le
**Objectif :** comprendre comment le mod√®le prend ses d√©cisions pour rendre les pr√©dictions transparentes et actionnables.

**Outils :**

- **SHAP** : explication globale et locale.
- **LIME** : interpr√©tation client par client.
- **Feature Importance** : impact moyen des variables sur le mod√®le.

**Insights cl√©s :**

- AgeCategory, NumOfProductsBinary et IsActiveMember sont les facteurs les plus influents.
- Les variables √©conomiques (solde, salaire, BalanceToSalaryRatio) mod√®rent les pr√©dictions.
- Analyse locale permet de cibler les actions de fid√©lisation pour chaque client.

---

## 10. Recommandations m√©tiers
1. **Suivi et monitoring** : surveiller les performances du mod√®le et d√©tecter la d√©rive des donn√©es.
2. **Actualisation des donn√©es** : int√©grer de nouvelles sources et mettre √† jour r√©guli√®rement les features.
3. **Optimisation des mod√®les** : tester XGBoost, LightGBM, r√©seaux de neurones, ou solutions AutoML.
4. **Automatisation de la fid√©lisation** : int√©gration CRM pour campagnes cibl√©es.
5. **Renforcement de l‚Äôexplicabilit√©** : usage continu de SHAP et LIME pour justifier les d√©cisions.
6. **Extension √† d‚Äôautres domaines** : pr√©diction de d√©faut, segmentation dynamique, portefeuille client.

---

## 11. Conclusion
Le projet XGBoost a permis de construire un **mod√®le pr√©dictif robuste, interpr√©table et op√©rationnel**, capable d‚Äôanticiper le churn avec fiabilit√©.  
Gr√¢ce √† son d√©ploiement via Streamlit, la banque dispose d√©sormais d‚Äôun outil pratique pour **optimiser la fid√©lisation client et la strat√©gie commerciale**.

---

## 12. √âtapes suivantes
- **Monitoring continu** du mod√®le et d√©tection de la d√©rive.
- **Mise √† jour r√©guli√®re** des donn√©es et des features.
- **Exploration de mod√®les hybrides et AutoML** pour am√©liorer la performance.
- **Int√©gration op√©rationnelle** dans les syst√®mes CRM pour actions automatis√©es.
- **Analyse continue de l‚Äôexplicabilit√©** pour renforcer la confiance des √©quipes.

---

*Analyse r√©alis√©e par Rich√© Fleurinord et Micka Louis ‚Äî Phase 5 : Projet Data Science & IA (Akademi)*  
¬© 2025 ‚Äî Pr√©diction du Churn Client avec XGBoost
